{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cc2cf7-31b8-4f29-8ce0-c22a1f8348ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.14.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.20.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2025.11.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8107e8f5-b98c-4712-b441-b141e22795dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading data... (this takes ~30-60s)\n",
      "✅ Loaded 41,663,872 rows.\n",
      "⏳ Resampling to 10-min bins... (this takes ~2-3 mins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_4594/1940551331.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tensor_df = df.groupby('stay_id').apply(process_stay)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "✅ TENSOR BUILT SUCCESSFULLY\n",
      "Shape: (28735, 144, 5) (Patients, TimeSteps, Features)\n",
      "Features order: ['HR', 'RR', 'SpO2', 'Temp', 'MAP']\n",
      "Saved to: data/Sample_2/tensor_10min_24h.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# 10 mins = 144 steps in 24 hours (24 * 60 / 10)\n",
    "BIN_SIZE = '10min' \n",
    "EXPECTED_STEPS = 144 \n",
    "\n",
    "# Paths (Based on your download structure)\n",
    "INPUT_FILE = \"data/Sample_2/chartevents_vaso_24h_post.csv.gz\"\n",
    "OUTPUT_TENSOR = \"data/Sample_2/tensor_10min_24h.pkl\"\n",
    "OUTPUT_IDS = \"data/Sample_2/tensor_stay_ids.pkl\"\n",
    "\n",
    "# 1. Load Data (Optimized)\n",
    "print(\"⏳ Loading data... (this takes ~30-60s)\")\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        INPUT_FILE, \n",
    "        compression=\"gzip\",\n",
    "        usecols=[\"stay_id\", \"itemid\", \"valuenum\", \"hours_since_vaso\"],\n",
    "        dtype_backend=\"pyarrow\" # drastically reduces RAM usage\n",
    "    )\n",
    "except ValueError:\n",
    "    # Fallback if pyarrow isn't installed/supported\n",
    "    df = pd.read_csv(\n",
    "        INPUT_FILE, \n",
    "        compression=\"gzip\",\n",
    "        usecols=[\"stay_id\", \"itemid\", \"valuenum\", \"hours_since_vaso\"]\n",
    "    )\n",
    "\n",
    "print(f\"✅ Loaded {len(df):,} rows.\")\n",
    "\n",
    "# 2. Map ItemIDs to Names\n",
    "# (Recreating the dictionary from your d_items file to be safe)\n",
    "d_items = pd.read_csv(\"data/Sample_2/d_items.csv.gz\")\n",
    "# Simple regex map for the 7 key vitals\n",
    "pattern_map = {\n",
    "    r\"Heart Rate|HR\": \"HR\",\n",
    "    r\"Respiratory Rate|RR\": \"RR\",\n",
    "    r\"O2 saturation|SpO2\": \"SpO2\",\n",
    "    r\"Mean Arterial Pressure|MAP|ABP mean\": \"MAP\",\n",
    "    r\"Systolic.*Blood Pressure|NBP systolic|NIBP systolic\": \"SBP\",\n",
    "    r\"Diastolic.*Blood Pressure|NBP diastolic|NIBP diastolic\": \"DBP\",\n",
    "    r\"Temperature|Temp\": \"Temp\",\n",
    "}\n",
    "def get_signal(label):\n",
    "    for pat, sig in pattern_map.items():\n",
    "        if pd.notna(label) and pd.Series(label).str.contains(pat, case=False, regex=True).any():\n",
    "            return sig\n",
    "    return None\n",
    "\n",
    "# Create mapping dict\n",
    "d_items['signal'] = d_items['label'].apply(get_signal)\n",
    "item_map = d_items.dropna(subset=['signal']).set_index('itemid')['signal'].to_dict()\n",
    "\n",
    "# Apply map & drop unused rows\n",
    "df['signal'] = df['itemid'].map(item_map)\n",
    "df = df.dropna(subset=['signal'])\n",
    "\n",
    "# 3. Convert time to Timedelta\n",
    "df['time_delta'] = pd.to_timedelta(df['hours_since_vaso'], unit='h')\n",
    "\n",
    "# 4. Resample (The Heavy Lift)\n",
    "print(\"⏳ Resampling to 10-min bins... (this takes ~2-3 mins)\")\n",
    "\n",
    "def process_stay(group):\n",
    "    # Pivot: Index=Time, Columns=Signals\n",
    "    # aggfunc='mean' handles multiple readings in same 10-min window\n",
    "    wide = group.pivot_table(index='time_delta', columns='signal', values='valuenum', aggfunc='mean')\n",
    "    \n",
    "    # Force fixed grid (0h to 24h)\n",
    "    full_idx = pd.timedelta_range(start='0h', end='24h', freq=BIN_SIZE, closed='left')\n",
    "    wide = wide.reindex(full_idx)\n",
    "    \n",
    "    # Forward Fill (carry last reading forward 1 hour max), then Backfill\n",
    "    wide = wide.ffill(limit=6).bfill()\n",
    "    \n",
    "    # Ensure we always return exactly 144 rows\n",
    "    return wide.iloc[:EXPECTED_STEPS]\n",
    "\n",
    "# Groupby apply is safer for memory than a full pivot\n",
    "tensor_df = df.groupby('stay_id').apply(process_stay)\n",
    "\n",
    "# 5. Formatting for Model\n",
    "# We need a 3D numpy array: (N_patients, 144, 7)\n",
    "unique_stays = tensor_df.index.get_level_values(0).unique()\n",
    "n_samples = len(unique_stays)\n",
    "n_features = len(tensor_df.columns)\n",
    "\n",
    "# Convert to numpy 3D array\n",
    "X_tensor = tensor_df.values.reshape(n_samples, EXPECTED_STEPS, n_features)\n",
    "\n",
    "# Save\n",
    "with open(OUTPUT_TENSOR, 'wb') as f:\n",
    "    pickle.dump(X_tensor, f)\n",
    "with open(OUTPUT_IDS, 'wb') as f:\n",
    "    pickle.dump(unique_stays.values, f)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"✅ TENSOR BUILT SUCCESSFULLY\")\n",
    "print(f\"Shape: {X_tensor.shape} (Patients, TimeSteps, Features)\")\n",
    "print(f\"Features order: {list(tensor_df.columns)}\")\n",
    "print(f\"Saved to: {OUTPUT_TENSOR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7f3649-09fd-4c15-9df8-55330de3c49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor IDs loaded: 28735\n",
      "Missing labels: 8422\n",
      "⚠️ Warning: Some tensor IDs have no label. Filling with 0 (Non-Hypotensive) for now.\n",
      "------------------------------\n",
      "✅ LABELS ALIGNED & SAVED\n",
      "Shape: (28735,)\n",
      "Class Balance: (array([0, 1]), array([12026, 16709]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the IDs that made it into the Tensor\n",
    "# (We must match this order exactly)\n",
    "with open(\"data/Sample_2/tensor_stay_ids.pkl\", 'rb') as f:\n",
    "    tensor_ids = pickle.load(f)\n",
    "\n",
    "print(f\"Tensor IDs loaded: {len(tensor_ids)}\")\n",
    "\n",
    "# 2. Load your Labeled Dataset\n",
    "# This file contains the 'hypotension_label' (0 or 1)\n",
    "labels_df = pd.read_csv(\n",
    "    \"data/Sample_2/merged_features_labeled_clean.csv.gz\",\n",
    "    usecols=[\"stay_id\", \"hypotension_label\"]\n",
    ")\n",
    "\n",
    "# 3. Align Labels to Tensor\n",
    "# Create a DataFrame indexed by the exact tensor ID order\n",
    "tensor_order = pd.DataFrame({\"stay_id\": tensor_ids})\n",
    "aligned_df = tensor_order.merge(labels_df, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# 4. Check for Missing Labels\n",
    "missing = aligned_df[\"hypotension_label\"].isna().sum()\n",
    "print(f\"Missing labels: {missing}\")\n",
    "\n",
    "# Fill NaN labels if any (rare edge case) or drop\n",
    "if missing > 0:\n",
    "    print(\"⚠️ Warning: Some tensor IDs have no label. Filling with 0 (Non-Hypotensive) for now.\")\n",
    "    aligned_df[\"hypotension_label\"] = aligned_df[\"hypotension_label\"].fillna(0)\n",
    "\n",
    "# 5. Save as Numpy Array 'y'\n",
    "y = aligned_df[\"hypotension_label\"].values.astype(int)\n",
    "with open(\"data/Sample_2/y_labels.pkl\", 'wb') as f:\n",
    "    pickle.dump(y, f)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"✅ LABELS ALIGNED & SAVED\")\n",
    "print(f\"Shape: {y.shape}\")\n",
    "print(f\"Class Balance: {np.unique(y, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e3f719-f538-4388-8ded-59a19f67371e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Building static features for 28735 patients...\n",
      "✅ Demographic files found. Merging...\n",
      "✅ Static features saved to: data/Sample_2/static_fairness_data.csv.gz\n",
      "------------------------------\n",
      "Preview of Static Data:\n",
      "    stay_id  anchor_age  is_male  race_enc\n",
      "0  37081114          86        0         1\n",
      "1  37510196          68        0         2\n",
      "2  39060235          53        0         0\n",
      "3  34672098          56        1         0\n",
      "4  35479615          80        0         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Updated to point to the correct \"_vaso\" file you created earlier\n",
    "INPUT_ICU = \"data/Sample_2/icustays_vaso.csv.gz\" \n",
    "\n",
    "# These two files must be downloaded from your source (Drive/PhysioNet) \n",
    "# and placed in data/Sample_2/ manually, as they weren't part of the vaso-sampling pipeline.\n",
    "INPUT_PATIENTS = \"data/Sample_2/patients.csv.gz\" \n",
    "INPUT_ADMISSIONS = \"data/Sample_2/admissions.csv.gz\"\n",
    "OUTPUT_STATIC = \"data/Sample_2/static_fairness_data.csv.gz\"\n",
    "\n",
    "# 1. Load Data\n",
    "# We only need the cohort that made it into our Tensor\n",
    "tensor_ids_path = \"data/Sample_2/tensor_stay_ids.pkl\"\n",
    "\n",
    "if not os.path.exists(tensor_ids_path):\n",
    "    raise FileNotFoundError(\"❌ tensor_stay_ids.pkl not found. Run the Time-Series Tensor script first.\")\n",
    "\n",
    "with open(tensor_ids_path, 'rb') as f:\n",
    "    valid_stay_ids = pickle.load(f)\n",
    "\n",
    "print(f\"⏳ Building static features for {len(valid_stay_ids)} patients...\")\n",
    "\n",
    "# Load ICU stays (using the vaso filtered file)\n",
    "icu = pd.read_csv(INPUT_ICU, compression='gzip', usecols=['stay_id', 'subject_id', 'hadm_id'])\n",
    "icu = icu[icu['stay_id'].isin(valid_stay_ids)]\n",
    "\n",
    "# 2. Merge Demographics\n",
    "if os.path.exists(INPUT_PATIENTS) and os.path.exists(INPUT_ADMISSIONS):\n",
    "    print(\"✅ Demographic files found. Merging...\")\n",
    "    pat = pd.read_csv(INPUT_PATIENTS, compression='gzip', usecols=['subject_id', 'gender', 'anchor_age'])\n",
    "    adm = pd.read_csv(INPUT_ADMISSIONS, compression='gzip', usecols=['subject_id', 'hadm_id', 'race'])\n",
    "    \n",
    "    # Merge\n",
    "    static = icu.merge(pat, on='subject_id', how='left')\n",
    "    static = static.merge(adm, on=['subject_id', 'hadm_id'], how='left')\n",
    "    \n",
    "    # 3. Encode for Model\n",
    "    # Gender: Male=1, Female=0\n",
    "    static['is_male'] = (static['gender'] == 'M').astype(int)\n",
    "    \n",
    "    # Race: Simplify to top groups for fairness analysis\n",
    "    def clean_race(r):\n",
    "        if pd.isna(r): return 0 # Other/Unknown\n",
    "        r = r.upper()\n",
    "        if 'WHITE' in r: return 1\n",
    "        if 'BLACK' in r: return 2\n",
    "        if 'HISPANIC' in r: return 3\n",
    "        if 'ASIAN' in r: return 4\n",
    "        return 0\n",
    "    \n",
    "    static['race_enc'] = static['race'].apply(clean_race)\n",
    "    \n",
    "    # Save\n",
    "    static.to_csv(OUTPUT_STATIC, index=False, compression='gzip')\n",
    "    print(f\"✅ Static features saved to: {OUTPUT_STATIC}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Preview of Static Data:\")\n",
    "    print(static[['stay_id', 'anchor_age', 'is_male', 'race_enc']].head())\n",
    "\n",
    "else:\n",
    "    print(\"❌ ERROR: Missing demographic files.\")\n",
    "    print(f\"Please download 'patients.csv.gz' and 'admissions.csv.gz' and upload them to: {os.path.abspath('data/Sample_2/')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cf494ba-4a1f-433d-904c-630eac8eeaa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.1)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.76.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.4/620.4 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (386 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, werkzeug, termcolor, tensorboard-data-server, optree, opt_einsum, ml_dtypes, markdown, h5py, google_pasta, gast, astunparse, tensorboard, keras, tensorflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [tensorflow]7\u001b[0m [tensorflow]]]ata-server]\n",
      "\u001b[1A\u001b[2KSuccessfully installed astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 h5py-3.15.1 keras-3.12.0 libclang-18.1.1 markdown-3.10 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 werkzeug-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7b33be5-bdf1-44dc-bec6-bfe0c1eac5de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading data...\n",
      "Dimensions Check: Tensor=28735, Static=28735, Labels=28735\n",
      "✅ Data Ready. Training on 22988 samples, Testing on 5747.\n",
      "Check for NaNs: 0 (Should be 0)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. LOAD AND PREPROCESS DATA (Final Fix)\n",
    "# ==========================================\n",
    "print(\"⏳ Loading data...\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load Time-Series (X_dynamic)\n",
    "with open(TENSOR_PATH, 'rb') as f:\n",
    "    X_dynamic = pickle.load(f)\n",
    "\n",
    "# --- FIX: Force conversion to numeric using 'coerce' ---\n",
    "# 1. Flatten to 2D\n",
    "n_samples, n_steps, n_features = X_dynamic.shape\n",
    "X_flat = X_dynamic.reshape(-1, n_features)\n",
    "\n",
    "# 2. Use apply(pd.to_numeric) with errors='coerce'\n",
    "# This forces stubborn 'pd.NA' types into standard 'np.nan' (float)\n",
    "X_flat = pd.DataFrame(X_flat).apply(pd.to_numeric, errors='coerce').values.astype(np.float32)\n",
    "\n",
    "# 3. Impute (Fill NaNs)\n",
    "# Neural networks cannot handle NaNs. We fill gaps with the column mean.\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_flat = imputer.fit_transform(X_flat)\n",
    "\n",
    "# 4. Scale (Standardize)\n",
    "scaler_dynamic = StandardScaler()\n",
    "X_flat = scaler_dynamic.fit_transform(X_flat)\n",
    "\n",
    "# 5. Reshape back to 3D\n",
    "X_dynamic = X_flat.reshape(n_samples, n_steps, n_features)\n",
    "\n",
    "# Load Labels (y)\n",
    "with open(LABEL_PATH, 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "\n",
    "# Load Static Features (X_static)\n",
    "static_df = pd.read_csv(STATIC_PATH)\n",
    "\n",
    "# Apply the same numeric coercion to static features just to be safe\n",
    "X_static = static_df[['anchor_age', 'is_male', 'race_enc']].apply(pd.to_numeric, errors='coerce').values.astype(np.float32)\n",
    "\n",
    "# Impute static data (in case of missing ages/demographics)\n",
    "X_static = imputer.fit_transform(X_static)\n",
    "\n",
    "# --- Data Alignment Check ---\n",
    "print(f\"Dimensions Check: Tensor={X_dynamic.shape[0]}, Static={X_static.shape[0]}, Labels={y.shape[0]}\")\n",
    "if not (X_dynamic.shape[0] == y.shape[0] == X_static.shape[0]):\n",
    "    raise ValueError(\"❌ Data dimension mismatch! Your Tensor, Labels, and Static data must have the same number of patients.\")\n",
    "\n",
    "# --- Train/Test Split ---\n",
    "X_dyn_train, X_dyn_test, X_stat_train, X_stat_test, y_train, y_test = train_test_split(\n",
    "    X_dynamic, X_static, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"✅ Data Ready. Training on {X_dyn_train.shape[0]} samples, Testing on {X_dyn_test.shape[0]}.\")\n",
    "print(f\"Check for NaNs: {np.isnan(X_dyn_train).sum()} (Should be 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4da71dab-07b0-4836-9cc9-4732c8c9efc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚖️ Class Weights: {0: 1.194678307868205, 1: 0.8598788060148126}\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 23:27:34.099113: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ time_series_input   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,949</span> │ time_series_inpu… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ time_series_inpu… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_series_inpu… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ static_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ time_series_input   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │      \u001b[38;5;34m2,949\u001b[0m │ time_series_inpu… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ time_series_inpu… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ time_series_inpu… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │         \u001b[38;5;34m10\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m384\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │        \u001b[38;5;34m325\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │         \u001b[38;5;34m10\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m64\u001b[0m │ static_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m704\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,479</span> (17.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,479\u001b[0m (17.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,479</span> (17.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,479\u001b[0m (17.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting Training...\n",
      "Epoch 1/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 167ms/step - AUC: 0.5090 - accuracy: 0.5346 - loss: 4.1087 - val_AUC: 0.5344 - val_accuracy: 0.4773 - val_loss: 0.7348\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/360\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 176ms/step - AUC: 0.5325 - accuracy: 0.4688 - loss: 2.8624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/callbacks/early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: AUC,accuracy,loss,val_AUC,val_accuracy,val_loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 165ms/step - AUC: 0.5048 - accuracy: 0.5031 - loss: 2.6687 - val_AUC: 0.5440 - val_accuracy: 0.4743 - val_loss: 0.7250\n",
      "Epoch 3/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 165ms/step - AUC: 0.5007 - accuracy: 0.4998 - loss: 2.1707 - val_AUC: 0.5582 - val_accuracy: 0.4764 - val_loss: 0.7083\n",
      "Epoch 4/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 167ms/step - AUC: 0.5038 - accuracy: 0.5022 - loss: 1.6744 - val_AUC: 0.5715 - val_accuracy: 0.5117 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 165ms/step - AUC: 0.5073 - accuracy: 0.5071 - loss: 1.2888 - val_AUC: 0.5773 - val_accuracy: 0.4963 - val_loss: 0.6914\n",
      "Epoch 6/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 167ms/step - AUC: 0.5186 - accuracy: 0.5178 - loss: 1.0029 - val_AUC: 0.5893 - val_accuracy: 0.5018 - val_loss: 0.6869\n",
      "Epoch 7/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 166ms/step - AUC: 0.5280 - accuracy: 0.5189 - loss: 0.8210 - val_AUC: 0.5886 - val_accuracy: 0.5465 - val_loss: 0.6762\n",
      "Epoch 8/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 167ms/step - AUC: 0.5467 - accuracy: 0.5257 - loss: 0.7308 - val_AUC: 0.5856 - val_accuracy: 0.5107 - val_loss: 0.6845\n",
      "Epoch 9/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 171ms/step - AUC: 0.5605 - accuracy: 0.5257 - loss: 0.7004 - val_AUC: 0.5884 - val_accuracy: 0.5565 - val_loss: 0.6720\n",
      "Epoch 10/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 169ms/step - AUC: 0.5785 - accuracy: 0.5387 - loss: 0.6849 - val_AUC: 0.5964 - val_accuracy: 0.5678 - val_loss: 0.6702\n",
      "Epoch 11/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 167ms/step - AUC: 0.5808 - accuracy: 0.5350 - loss: 0.6803 - val_AUC: 0.5984 - val_accuracy: 0.5770 - val_loss: 0.6666\n",
      "Epoch 12/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 168ms/step - AUC: 0.5934 - accuracy: 0.5504 - loss: 0.6763 - val_AUC: 0.6013 - val_accuracy: 0.5859 - val_loss: 0.6627\n",
      "Epoch 13/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 171ms/step - AUC: 0.5999 - accuracy: 0.5500 - loss: 0.6736 - val_AUC: 0.6022 - val_accuracy: 0.5208 - val_loss: 0.6860\n",
      "Epoch 14/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 166ms/step - AUC: 0.6034 - accuracy: 0.5499 - loss: 0.6719 - val_AUC: 0.6130 - val_accuracy: 0.5211 - val_loss: 0.6866\n",
      "Epoch 15/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 167ms/step - AUC: 0.6039 - accuracy: 0.5510 - loss: 0.6715 - val_AUC: 0.6006 - val_accuracy: 0.5798 - val_loss: 0.6630\n",
      "Epoch 16/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 166ms/step - AUC: 0.6042 - accuracy: 0.5462 - loss: 0.6706 - val_AUC: 0.6061 - val_accuracy: 0.5279 - val_loss: 0.6735\n",
      "Epoch 17/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 167ms/step - AUC: 0.6053 - accuracy: 0.5509 - loss: 0.6703 - val_AUC: 0.6048 - val_accuracy: 0.5189 - val_loss: 0.6794\n",
      "Epoch 18/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 167ms/step - AUC: 0.6058 - accuracy: 0.5467 - loss: 0.6693 - val_AUC: 0.6108 - val_accuracy: 0.5229 - val_loss: 0.6788\n",
      "Epoch 19/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 169ms/step - AUC: 0.6063 - accuracy: 0.5446 - loss: 0.6685 - val_AUC: 0.6126 - val_accuracy: 0.5290 - val_loss: 0.6771\n",
      "Epoch 20/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 168ms/step - AUC: 0.6055 - accuracy: 0.5483 - loss: 0.6697 - val_AUC: 0.6009 - val_accuracy: 0.5817 - val_loss: 0.6628\n",
      "✅ Training Complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ==========================================\n",
    "# 2. CALCULATE CLASS WEIGHTS\n",
    "# ==========================================\n",
    "# This balances the loss function so the model doesn't just predict the majority class\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"⚖️ Class Weights: {class_weight_dict}\")\n",
    "# You will likely see {0: ~2.8, 1: ~0.6} because Stable (0) is rare in this cohort.\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. BUILD THE HYBRID TRANSFORMER ARCHITECTURE\n",
    "# ==========================================\n",
    "def build_hybrid_transformer(input_shape_dyn, input_shape_stat):\n",
    "    # --- Branch A: Time-Series (The \"Movie\") ---\n",
    "    input_dynamic = keras.Input(shape=input_shape_dyn, name=\"time_series_input\")\n",
    "    \n",
    "    # 1. Transformer Block\n",
    "    # Self-Attention: Finds relationships between different time steps (e.g., Hour 2 vs Hour 23)\n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "        num_heads=4, key_dim=32, dropout=0.1\n",
    "    )(input_dynamic, input_dynamic)\n",
    "    \n",
    "    # Add & Normalize (Standard Deep Learning stabilization)\n",
    "    x1 = layers.Add()([input_dynamic, attention_output])\n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(x1)\n",
    "    \n",
    "    # Feed Forward Network (The \"Reasoning\" part)\n",
    "    x2 = layers.Conv1D(filters=64, kernel_size=1, activation=\"relu\")(x1)\n",
    "    x2 = layers.Dropout(0.1)(x2)\n",
    "    x2 = layers.Conv1D(filters=input_shape_dyn[-1], kernel_size=1)(x2)\n",
    "    \n",
    "    # Add & Normalize again\n",
    "    transformer_output = layers.Add()([x1, x2])\n",
    "    transformer_output = layers.LayerNormalization(epsilon=1e-6)(transformer_output)\n",
    "    \n",
    "    # Global Pooling: Squashes 144 time steps into one summary vector\n",
    "    dynamic_features = layers.GlobalAveragePooling1D()(transformer_output)\n",
    "\n",
    "    # --- Branch B: Static Features (The \"Context\") ---\n",
    "    # Processes Age, Gender, Race\n",
    "    input_static = keras.Input(shape=input_shape_stat, name=\"static_input\")\n",
    "    x_static = layers.Dense(16, activation=\"relu\")(input_static)\n",
    "    \n",
    "    # --- Fusion Layer ---\n",
    "    # Concatenate (glue) the dynamic summary and static context together\n",
    "    concat = layers.Concatenate()([dynamic_features, x_static])\n",
    "    \n",
    "    # Final Decision Layers\n",
    "    x = layers.Dense(32, activation=\"relu\")(concat)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1, activation=\"sigmoid\", name=\"prediction\")(x)\n",
    "\n",
    "    # Compile Model\n",
    "    model = keras.Model(inputs=[input_dynamic, input_static], outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Conservative learning rate\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"AUC\", \"accuracy\"] # AUC is our primary research metric\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Construct the model instance\n",
    "model = build_hybrid_transformer(\n",
    "    input_shape_dyn=(X_dyn_train.shape[1], X_dyn_train.shape[2]), # (144, 5)\n",
    "    input_shape_stat=(X_stat_train.shape[1],)                     # (3,)\n",
    ")\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAIN THE MODEL\n",
    "# ==========================================\n",
    "print(\"\\n🚀 Starting Training...\")\n",
    "history = model.fit(\n",
    "    x=[X_dyn_train, X_stat_train],   # Two inputs: Dynamic + Static\n",
    "    y=y_train,\n",
    "    validation_data=([X_dyn_test, X_stat_test], y_test),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight_dict,  # Apply the weights we calculated\n",
    "    callbacks=[\n",
    "        # Stop if validation AUC doesn't improve for 5 epochs\n",
    "        keras.callbacks.EarlyStopping(monitor='val_auc', mode='max', patience=5, restore_best_weights=True)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"✅ Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e906f75b-76e5-41f7-a975-cafdd2de7daf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 RUNNING FAIRNESS ANALYSIS...\n",
      "\n",
      "📊 FAIRNESS REPORT (Transformer Model)\n",
      "------------------------------------------------------------\n",
      "| Subgroup       |    N |   AUC |   FPR (False Alarm) |   FNR (Missed Case) |\n",
      "|:---------------|-----:|------:|--------------------:|--------------------:|\n",
      "| OVERALL        | 5747 | 0.601 |               0.741 |               0.186 |\n",
      "| Gender: Male   | 3472 | 0.612 |               0.734 |               0.188 |\n",
      "| Gender: Female | 2275 | 0.582 |               0.751 |               0.183 |\n",
      "| Race: White    | 3850 | 0.603 |               0.76  |               0.176 |\n",
      "| Race: Black    |  462 | 0.576 |               0.704 |               0.218 |\n",
      "| Race: Hispanic |  213 | 0.62  |               0.698 |               0.213 |\n",
      "| Race: Asian    |  164 | 0.596 |               0.671 |               0.239 |\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "# ==========================================\n",
    "# 1. VISUALIZE LEARNING CURVES\n",
    "# ==========================================\n",
    "def plot_history(history):\n",
    "    acc = history.history['AUC']\n",
    "    val_acc = history.history['val_AUC']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot AUC\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training AUC')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation AUC')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation AUC')\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the curves from your training variable 'history'\n",
    "plot_history(history)\n",
    "\n",
    "# ==========================================\n",
    "# 2. FAIRNESS ANALYSIS (The Research Gap)\n",
    "# ==========================================\n",
    "print(\"\\n🔍 RUNNING FAIRNESS ANALYSIS...\")\n",
    "\n",
    "# A. Get Predictions\n",
    "# We use the test set we created earlier (X_dyn_test, X_stat_test, y_test)\n",
    "y_pred_proba = model.predict([X_dyn_test, X_stat_test], verbose=0).flatten()\n",
    "# Threshold: You can lower this to 0.3 or 0.4 later to catch more cases\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int) \n",
    "\n",
    "# B. Reconstruct the Test DataFrame\n",
    "# We need to know WHICH patient belongs to WHICH demographic in the test set\n",
    "# We can reverse-engineer this from X_stat_test\n",
    "# X_stat_test columns: [0: Age (Scaled), 1: Is_Male, 2: Race_Enc]\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_pred': y_pred,\n",
    "    'y_proba': y_pred_proba,\n",
    "    'is_male': X_stat_test[:, 1],\n",
    "    'race_enc': X_stat_test[:, 2]\n",
    "})\n",
    "\n",
    "# Decode Race (0=Other, 1=White, 2=Black, 3=Hispanic, 4=Asian)\n",
    "race_map = {0: 'Other/Unknown', 1: 'White', 2: 'Black', 3: 'Hispanic', 4: 'Asian'}\n",
    "test_df['Race'] = test_df['race_enc'].map(race_map)\n",
    "\n",
    "# Decode Gender\n",
    "test_df['Gender'] = test_df['is_male'].apply(lambda x: 'Male' if x == 1 else 'Female')\n",
    "\n",
    "# C. Define Metrics Function\n",
    "def get_metrics(df_sub):\n",
    "    if len(df_sub) == 0: return {'N': 0}\n",
    "    y_t = df_sub['y_true']\n",
    "    y_p = df_sub['y_pred']\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(y_t, df_sub['y_proba'])\n",
    "    except:\n",
    "        auc = 0.0 # Handle edge case if only 1 class exists\n",
    "        \n",
    "    tn, fp, fn, tp = confusion_matrix(y_t, y_p, labels=[0,1]).ravel()\n",
    "    \n",
    "    # False Positive Rate (False Alarm Rate) = FP / (FP + TN)\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    # False Negative Rate (Missed Diagnosis Rate) = FN / (FN + TP)\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'N': len(df_sub),\n",
    "        'AUC': round(auc, 3),\n",
    "        'FPR (False Alarm)': round(fpr, 3),\n",
    "        'FNR (Missed Case)': round(fnr, 3)\n",
    "    }\n",
    "\n",
    "# D. Analyze by Subgroup\n",
    "results = []\n",
    "\n",
    "# Overall\n",
    "results.append({'Subgroup': 'OVERALL', **get_metrics(test_df)})\n",
    "\n",
    "# By Gender\n",
    "for g in ['Male', 'Female']:\n",
    "    sub = test_df[test_df['Gender'] == g]\n",
    "    results.append({'Subgroup': f'Gender: {g}', **get_metrics(sub)})\n",
    "\n",
    "# By Race\n",
    "for r in ['White', 'Black', 'Hispanic', 'Asian']:\n",
    "    sub = test_df[test_df['Race'] == r]\n",
    "    results.append({'Subgroup': f'Race: {r}', **get_metrics(sub)})\n",
    "\n",
    "# E. Display\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n📊 FAIRNESS REPORT (Transformer Model)\")\n",
    "print(\"-\" * 60)\n",
    "print(results_df[['Subgroup', 'N', 'AUC', 'FPR (False Alarm)', 'FNR (Missed Case)']].to_markdown(index=False))\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d138e72-7d2e-4f0e-abd2-a42deda131e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ time_series_input   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,949</span> │ time_series_inpu… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ time_series_inpu… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_series_inpu… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,949</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ static_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ time_series_input   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │      \u001b[38;5;34m2,949\u001b[0m │ time_series_inpu… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ time_series_inpu… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ time_series_inpu… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │         \u001b[38;5;34m10\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m384\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │        \u001b[38;5;34m325\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │         \u001b[38;5;34m10\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │      \u001b[38;5;34m2,949\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │         \u001b[38;5;34m10\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m384\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │        \u001b[38;5;34m325\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │         \u001b[38;5;34m10\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m64\u001b[0m │ static_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,408\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,941</span> (42.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,941\u001b[0m (42.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,941</span> (42.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,941\u001b[0m (42.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting Training (V2 with Focal Loss)...\n",
      "Epoch 1/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 334ms/step - AUC: 0.5060 - accuracy: 0.4543 - loss: 0.1520 - val_AUC: 0.4859 - val_accuracy: 0.4185 - val_loss: 0.0813 - learning_rate: 5.0000e-04\n",
      "Epoch 2/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 333ms/step - AUC: 0.4989 - accuracy: 0.4239 - loss: 0.0822 - val_AUC: 0.5025 - val_accuracy: 0.4185 - val_loss: 0.0765 - learning_rate: 5.0000e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 333ms/step - AUC: 0.4993 - accuracy: 0.4206 - loss: 0.0760 - val_AUC: 0.5038 - val_accuracy: 0.4185 - val_loss: 0.0733 - learning_rate: 5.0000e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 338ms/step - AUC: 0.5105 - accuracy: 0.4193 - loss: 0.0733 - val_AUC: 0.5508 - val_accuracy: 0.4185 - val_loss: 0.0715 - learning_rate: 5.0000e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - AUC: 0.5415 - accuracy: 0.4212 - loss: 0.0714 - val_AUC: 0.5779 - val_accuracy: 0.4185 - val_loss: 0.0702 - learning_rate: 5.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - AUC: 0.5656 - accuracy: 0.4289 - loss: 0.0700 - val_AUC: 0.5884 - val_accuracy: 0.4185 - val_loss: 0.0689 - learning_rate: 5.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 339ms/step - AUC: 0.5771 - accuracy: 0.4421 - loss: 0.0690 - val_AUC: 0.5649 - val_accuracy: 0.4185 - val_loss: 0.0689 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 336ms/step - AUC: 0.5709 - accuracy: 0.4419 - loss: 0.0686 - val_AUC: 0.5702 - val_accuracy: 0.4700 - val_loss: 0.0681 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 333ms/step - AUC: 0.5702 - accuracy: 0.4471 - loss: 0.0682 - val_AUC: 0.5984 - val_accuracy: 0.4185 - val_loss: 0.0674 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 333ms/step - AUC: 0.5794 - accuracy: 0.4459 - loss: 0.0676 - val_AUC: 0.5952 - val_accuracy: 0.4199 - val_loss: 0.0670 - learning_rate: 5.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 348ms/step - AUC: 0.5814 - accuracy: 0.4479 - loss: 0.0672 - val_AUC: 0.5945 - val_accuracy: 0.4272 - val_loss: 0.0664 - learning_rate: 5.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 334ms/step - AUC: 0.5836 - accuracy: 0.4584 - loss: 0.0667 - val_AUC: 0.5994 - val_accuracy: 0.4185 - val_loss: 0.0665 - learning_rate: 5.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - AUC: 0.5837 - accuracy: 0.4572 - loss: 0.0665 - val_AUC: 0.5817 - val_accuracy: 0.4836 - val_loss: 0.0659 - learning_rate: 5.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 332ms/step - AUC: 0.5851 - accuracy: 0.4637 - loss: 0.0661 - val_AUC: 0.6035 - val_accuracy: 0.5003 - val_loss: 0.0654 - learning_rate: 5.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 337ms/step - AUC: 0.5907 - accuracy: 0.4663 - loss: 0.0659 - val_AUC: 0.5991 - val_accuracy: 0.4933 - val_loss: 0.0655 - learning_rate: 5.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 342ms/step - AUC: 0.5936 - accuracy: 0.4663 - loss: 0.0655 - val_AUC: 0.6086 - val_accuracy: 0.4983 - val_loss: 0.0649 - learning_rate: 5.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 333ms/step - AUC: 0.5944 - accuracy: 0.4717 - loss: 0.0653 - val_AUC: 0.5998 - val_accuracy: 0.4827 - val_loss: 0.0648 - learning_rate: 5.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 349ms/step - AUC: 0.5941 - accuracy: 0.4739 - loss: 0.0651 - val_AUC: 0.6091 - val_accuracy: 0.4872 - val_loss: 0.0646 - learning_rate: 5.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 343ms/step - AUC: 0.5869 - accuracy: 0.4662 - loss: 0.0652 - val_AUC: 0.6026 - val_accuracy: 0.5001 - val_loss: 0.0645 - learning_rate: 5.0000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 349ms/step - AUC: 0.6021 - accuracy: 0.4775 - loss: 0.0647 - val_AUC: 0.6021 - val_accuracy: 0.4803 - val_loss: 0.0646 - learning_rate: 5.0000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - AUC: 0.5947 - accuracy: 0.4788 - loss: 0.0647\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 339ms/step - AUC: 0.6006 - accuracy: 0.4765 - loss: 0.0647 - val_AUC: 0.6072 - val_accuracy: 0.4195 - val_loss: 0.0645 - learning_rate: 5.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - AUC: 0.6048 - accuracy: 0.4774 - loss: 0.0643 - val_AUC: 0.5993 - val_accuracy: 0.4910 - val_loss: 0.0642 - learning_rate: 2.5000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 343ms/step - AUC: 0.6083 - accuracy: 0.4829 - loss: 0.0642 - val_AUC: 0.6070 - val_accuracy: 0.4912 - val_loss: 0.0640 - learning_rate: 2.5000e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - AUC: 0.6077 - accuracy: 0.4823 - loss: 0.0642\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - AUC: 0.6065 - accuracy: 0.4830 - loss: 0.0642 - val_AUC: 0.6055 - val_accuracy: 0.4870 - val_loss: 0.0640 - learning_rate: 2.5000e-04\n",
      "✅ V2 Training Complete.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ==========================================\n",
    "# 1. DEFINE FOCAL LOSS\n",
    "# ==========================================\n",
    "# Gamma=2.0 focuses heavily on hard examples. Alpha=0.25 balances the classes.\n",
    "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = keras.backend.epsilon()\n",
    "        y_pred = keras.backend.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        \n",
    "        alpha_t = y_true * alpha + (keras.backend.ones_like(y_true) - y_true) * (1 - alpha)\n",
    "        p_t = y_true * y_pred + (keras.backend.ones_like(y_true) - y_true) * (1 - y_pred)\n",
    "        fl = - alpha_t * keras.backend.pow((keras.backend.ones_like(y_true) - p_t), gamma) * keras.backend.log(p_t)\n",
    "        \n",
    "        return keras.backend.mean(fl)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# ==========================================\n",
    "# 2. BUILD IMPROVED TRANSFORMER (V2)\n",
    "# ==========================================\n",
    "def build_improved_transformer(input_shape_dyn, input_shape_stat):\n",
    "    # --- Branch A: Time-Series ---\n",
    "    input_dynamic = keras.Input(shape=input_shape_dyn, name=\"time_series_input\")\n",
    "    \n",
    "    x = input_dynamic\n",
    "    \n",
    "    # Stack 2 Transformer Blocks for deeper learning\n",
    "    for i in range(2):\n",
    "        # Multi-Head Attention\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=4, key_dim=32, dropout=0.1\n",
    "        )(x, x)\n",
    "        \n",
    "        # Add & Norm\n",
    "        x1 = layers.Add()([x, attention_output])\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x1)\n",
    "        \n",
    "        # Feed Forward\n",
    "        x2 = layers.Conv1D(filters=64, kernel_size=1, activation=\"relu\")(x1)\n",
    "        x2 = layers.Dropout(0.1)(x2)\n",
    "        x2 = layers.Conv1D(filters=input_shape_dyn[-1], kernel_size=1)(x2)\n",
    "        \n",
    "        # Add & Norm\n",
    "        x = layers.Add()([x1, x2])\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    # Global Pooling\n",
    "    dynamic_features = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # --- Branch B: Static Features ---\n",
    "    input_static = keras.Input(shape=input_shape_stat, name=\"static_input\")\n",
    "    x_static = layers.Dense(16, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(input_static)\n",
    "    \n",
    "    # --- Fusion ---\n",
    "    concat = layers.Concatenate()([dynamic_features, x_static])\n",
    "    \n",
    "    # Deeper Classification Head\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(concat)\n",
    "    x = layers.Dropout(0.3)(x) # Higher dropout to prevent overfitting\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    \n",
    "    output = layers.Dense(1, activation=\"sigmoid\", name=\"prediction\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input_dynamic, input_static], outputs=output)\n",
    "    \n",
    "    # Compile with FOCAL LOSS (No class_weights needed in .fit() if we use this)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0005), # Slightly higher LR for focal loss\n",
    "        loss=binary_focal_loss(gamma=2.0, alpha=0.20), # Alpha < 0.5 penalizes majority class\n",
    "        metrics=[\"AUC\", \"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Build\n",
    "model_v2 = build_improved_transformer(\n",
    "    input_shape_dyn=(X_dyn_train.shape[1], X_dyn_train.shape[2]),\n",
    "    input_shape_stat=(X_stat_train.shape[1],)\n",
    ")\n",
    "\n",
    "model_v2.summary()\n",
    "\n",
    "# ==========================================\n",
    "# 3. TRAIN V2 MODEL\n",
    "# ==========================================\n",
    "print(\"\\n🚀 Starting Training (V2 with Focal Loss)...\")\n",
    "# Note: We REMOVE class_weights because Focal Loss handles the imbalance internally\n",
    "history_v2 = model_v2.fit(\n",
    "    x=[X_dyn_train, X_stat_train],\n",
    "    y=y_train,\n",
    "    validation_data=([X_dyn_test, X_stat_test], y_test),\n",
    "    epochs=25, # Give it a bit more time\n",
    "    batch_size=64,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_AUC', mode='max', patience=6, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_AUC', factor=0.5, patience=3, verbose=1)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"✅ V2 Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c565532d-4b73-4174-9597-f5f0964dcd07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/google/auth/_default.py:108: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Authenticated as: pushpraj@bu.edu\n"
     ]
    }
   ],
   "source": [
    "import google.auth\n",
    "import google.auth.jwt\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "# 1. Get credentials\n",
    "credentials, project = google.auth.default()\n",
    "\n",
    "# 2. Refresh to ensure the token is populated\n",
    "credentials.refresh(Request())\n",
    "\n",
    "# 3. Decode the ID token to get the email\n",
    "if hasattr(credentials, 'id_token') and credentials.id_token:\n",
    "    # Decode the JWT string (verify=False allows peeking without checking audience)\n",
    "    decoded_token = google.auth.jwt.decode(credentials.id_token, verify=False)\n",
    "    print(f\"✅ Authenticated as: {decoded_token.get('email')}\")\n",
    "elif hasattr(credentials, 'service_account_email'):\n",
    "    # Fallback for Service Accounts\n",
    "    print(f\"✅ Authenticated as: {credentials.service_account_email}\")\n",
    "else:\n",
    "    print(\"✅ Authenticated (Email not found in token)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e2a513-1364-4a2a-8005-431a9cd8f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/google/auth/_default.py:108: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading cohort IDs...\n",
      "🎯 Target Cohort: 24,328 patients, 27,231 admissions.\n",
      "⏳ Fetching diagnoses for 27231 admissions...\n",
      "   Batch 1 done...\n",
      "   Batch 6 done...\n",
      "   Batch 11 done...\n",
      "✅ Saved diagnoses_icd_vaso.csv.gz (564,053 rows)\n",
      "⏳ Fetching specific LABS...\n",
      "   Labs Batch 1 done...\n",
      "   Labs Batch 6 done...\n",
      "   Labs Batch 11 done...\n",
      "✅ Saved labevents_vaso.csv.gz (8,541,160 rows)\n",
      "------------------------------\n",
      "🎉 Download complete.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# 🛑 REPLACE WITH YOUR PERSONAL PROJECT ID (all lowercase)\n",
    "MY_BILLING_PROJECT = \"icu-hypotension\"\n",
    "\n",
    "# MIMIC-IV v3.1 Data Location\n",
    "PHYSIONET_PROJECT = \"physionet-data\"\n",
    "DATASET = \"mimiciv_3_1_hosp\"  # Both diagnoses and labs are here\n",
    "TARGET_DIR = \"data/Sample_2\"\n",
    "\n",
    "# Initialize Client\n",
    "client = bigquery.Client(project=MY_BILLING_PROJECT)\n",
    "\n",
    "# --- 1. LOAD COHORT ---\n",
    "print(\"⏳ Loading cohort IDs...\")\n",
    "cohort_path = f\"{TARGET_DIR}/icustays_vaso.csv.gz\"\n",
    "if not os.path.exists(cohort_path):\n",
    "    raise FileNotFoundError(f\"❌ Missing {cohort_path}. Run the previous notebook steps first.\")\n",
    "\n",
    "cohort = pd.read_csv(cohort_path, usecols=['subject_id', 'hadm_id'])\n",
    "unique_subjects = cohort['subject_id'].unique().tolist()\n",
    "unique_hadms = cohort['hadm_id'].unique().tolist()\n",
    "\n",
    "print(f\"🎯 Target Cohort: {len(unique_subjects):,} patients, {len(unique_hadms):,} admissions.\")\n",
    "\n",
    "# --- 2. FETCH DIAGNOSES (Patient History) ---\n",
    "# Table: diagnoses_icd (Contains subject_id, hadm_id, icd_code)\n",
    "print(f\"⏳ Fetching diagnoses for {len(unique_hadms)} admissions...\")\n",
    "\n",
    "# Chunking to avoid query limits\n",
    "diag_frames = []\n",
    "chunk_size = 2000\n",
    "\n",
    "for i in range(0, len(unique_hadms), chunk_size):\n",
    "    batch = unique_hadms[i : i + chunk_size]\n",
    "    ids_str = \", \".join(map(str, batch))\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT subject_id, hadm_id, icd_code, icd_version\n",
    "        FROM `{PHYSIONET_PROJECT}.{DATASET}.diagnoses_icd`\n",
    "        WHERE hadm_id IN ({ids_str})\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = client.query(query).to_dataframe()\n",
    "        diag_frames.append(df)\n",
    "        if (i // chunk_size) % 5 == 0: print(f\"   Batch {i//chunk_size + 1} done...\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error on batch {i}: {e}\")\n",
    "\n",
    "if diag_frames:\n",
    "    diag_df = pd.concat(diag_frames, ignore_index=True)\n",
    "    diag_df.to_csv(f\"{TARGET_DIR}/diagnoses_icd_vaso.csv.gz\", index=False, compression='gzip')\n",
    "    print(f\"✅ Saved diagnoses_icd_vaso.csv.gz ({len(diag_df):,} rows)\")\n",
    "\n",
    "# --- 3. FETCH LAB EVENTS (Dynamic Vitals) ---\n",
    "# Table: labevents (Contains charttime, valuenum, itemid)\n",
    "# Filter: Lactate(50813), Creatinine(50912), WBC(51301), Platelets(51265), \n",
    "#         pH(50820), Hct(51221), Potassium(50971), Glucose(50931), BUN(51006)\n",
    "LAB_ITEMIDS = (50813, 50912, 51301, 51265, 50820, 51221, 50971, 50931, 51006)\n",
    "lab_ids_str = \", \".join(map(str, LAB_ITEMIDS))\n",
    "\n",
    "print(f\"⏳ Fetching specific LABS...\")\n",
    "lab_frames = []\n",
    "\n",
    "for i in range(0, len(unique_subjects), chunk_size):\n",
    "    batch = unique_subjects[i : i + chunk_size]\n",
    "    ids_str = \", \".join(map(str, batch))\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT subject_id, hadm_id, itemid, charttime, valuenum, valueuom\n",
    "        FROM `{PHYSIONET_PROJECT}.{DATASET}.labevents`\n",
    "        WHERE subject_id IN ({ids_str})\n",
    "        AND itemid IN ({lab_ids_str})\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = client.query(query).to_dataframe()\n",
    "        lab_frames.append(df)\n",
    "        if (i // chunk_size) % 5 == 0: print(f\"   Labs Batch {i//chunk_size + 1} done...\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error on labs batch {i}: {e}\")\n",
    "\n",
    "if lab_frames:\n",
    "    labs_df = pd.concat(lab_frames, ignore_index=True)\n",
    "    labs_df.to_csv(f\"{TARGET_DIR}/labevents_vaso.csv.gz\", index=False, compression='gzip')\n",
    "    print(f\"✅ Saved labevents_vaso.csv.gz ({len(labs_df):,} rows)\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"🎉 Download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e65f296-a2aa-44c0-8361-f557493fc0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Processing Diagnoses...\n",
      "✅ Added 5 diagnosis flags. New shape: (28735, 13)\n",
      "    stay_id  is_sepsis  is_heart_failure\n",
      "0  37081114          0                 1\n",
      "1  37510196          0                 0\n",
      "2  39060235          0                 1\n",
      "3  34672098          0                 0\n",
      "4  35479615          1                 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIG ---\n",
    "DATA_DIR = \"data/Sample_2\"\n",
    "INPUT_DIAG = f\"{DATA_DIR}/diagnoses_icd_vaso.csv.gz\"\n",
    "INPUT_STATIC = f\"{DATA_DIR}/static_fairness_data.csv.gz\"\n",
    "INPUT_ICU = f\"{DATA_DIR}/icustays_vaso.csv.gz\"\n",
    "\n",
    "print(\"⏳ Processing Diagnoses...\")\n",
    "\n",
    "# 1. Load Data\n",
    "diag = pd.read_csv(INPUT_DIAG)\n",
    "static = pd.read_csv(INPUT_STATIC)\n",
    "icu = pd.read_csv(INPUT_ICU, usecols=['stay_id', 'hadm_id'])\n",
    "\n",
    "# 2. Define Diagnosis Definitions (ICD-9 & ICD-10 prefixes)\n",
    "# You can expand this list later!\n",
    "diag_map = {\n",
    "    'is_sepsis': ['99591', '99592', 'A41', 'R652'], \n",
    "    'is_heart_failure': ['428', 'I50'],\n",
    "    'is_pneumonia': ['480', '481', '482', '483', '484', '485', '486', '487', '488', 'J12', 'J13', 'J14', 'J15', 'J16', 'J17', 'J18'],\n",
    "    'is_renal_failure': ['584', 'N17'],\n",
    "    'is_liver_disease': ['571', 'K70', 'K71', 'K72', 'K73', 'K74']\n",
    "}\n",
    "\n",
    "# 3. Create Flags\n",
    "# We map diagnoses to stays via hadm_id\n",
    "stay_diagnoses = icu[['stay_id', 'hadm_id']].copy()\n",
    "\n",
    "for col, codes in diag_map.items():\n",
    "    # Find all hadm_ids that have ANY of the codes in the list\n",
    "    # We check if the ICD code starts with the prefix (e.g. \"428\" catches \"428.0\", \"428.1\")\n",
    "    pattern = '|'.join([f\"^{c}\" for c in codes])\n",
    "    matched_hadms = diag[diag['icd_code'].astype(str).str.contains(pattern, regex=True)]['hadm_id'].unique()\n",
    "    \n",
    "    # Set flag to 1 if hadm_id is in the match list\n",
    "    stay_diagnoses[col] = stay_diagnoses['hadm_id'].isin(matched_hadms).astype(int)\n",
    "\n",
    "# Drop hadm_id as we merge on stay_id\n",
    "stay_diagnoses = stay_diagnoses.drop(columns=['hadm_id'])\n",
    "\n",
    "# 4. Merge with Existing Static Data\n",
    "# (Left merge ensures we keep all patients in our cohort, filling 0 for missing diagnoses)\n",
    "static_updated = static.merge(stay_diagnoses, on='stay_id', how='left')\n",
    "static_updated[list(diag_map.keys())] = static_updated[list(diag_map.keys())].fillna(0).astype(int)\n",
    "\n",
    "# 5. Save\n",
    "static_updated.to_csv(INPUT_STATIC, index=False, compression='gzip')\n",
    "print(f\"✅ Added {len(diag_map)} diagnosis flags. New shape: {static_updated.shape}\")\n",
    "print(static_updated[['stay_id', 'is_sepsis', 'is_heart_failure']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f665b3b2-99d8-4928-88de-06ec722209d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading vitals...\n",
      "✅ Mapped 7 signals. Unique stay_ids: 28,736\n",
      "⏳ Resampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_80331/1700475935.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tensor_df = df.groupby('stay_id').apply(process_stay)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "✅ Fixed Tensor Shape: (28736, 144, 9)\n",
      "Features: ['DBP', 'HR', 'MAP', 'RR', 'SBP', 'SpO2', 'Shock_Index', 'Pulse_Pressure', 'Temp']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# --- CONFIG ---\n",
    "BIN_SIZE = '10min'\n",
    "EXPECTED_STEPS = 144\n",
    "INPUT_FILE = \"data/Sample_2/chartevents_vaso_24h_post.csv.gz\"\n",
    "OUTPUT_TENSOR = \"data/Sample_2/tensor_10min_w_labs.pkl\" # Overwriting the old one\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"⏳ Loading vitals...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE, compression=\"gzip\", usecols=[\"stay_id\", \"itemid\", \"valuenum\", \"hours_since_vaso\"], dtype_backend=\"pyarrow\")\n",
    "except:\n",
    "    df = pd.read_csv(INPUT_FILE, compression=\"gzip\", usecols=[\"stay_id\", \"itemid\", \"valuenum\", \"hours_since_vaso\"])\n",
    "\n",
    "# 2. FIXED MAP (The Critical Change)\n",
    "d_items = pd.read_csv(\"data/Sample_2/d_items.csv.gz\")\n",
    "pattern_map = {\n",
    "    r\"Heart Rate|HR\": \"HR\",\n",
    "    r\"Respiratory Rate|RR\": \"RR\",\n",
    "    r\"O2 saturation|SpO2\": \"SpO2\",\n",
    "    r\"Temperature|Temp\": \"Temp\",\n",
    "    # ✅ FIX: Match \"Blood Pressure\" first, then \"Mean/Systolic\"\n",
    "    r\"Mean Arterial Pressure|MAP|ABP mean|Blood Pressure.*mean\": \"MAP\",\n",
    "    r\"Systolic.*Blood Pressure|Blood Pressure.*Systolic|NBP S\": \"SBP\",\n",
    "    r\"Diastolic.*Blood Pressure|Blood Pressure.*Diastolic|NBP D\": \"DBP\",\n",
    "}\n",
    "def get_signal(label):\n",
    "    for pat, sig in pattern_map.items():\n",
    "        if pd.notna(label) and pd.Series(label).str.contains(pat, case=False, regex=True).any():\n",
    "            return sig\n",
    "    return None\n",
    "\n",
    "d_items['signal'] = d_items['label'].apply(get_signal)\n",
    "item_map = d_items.dropna(subset=['signal']).set_index('itemid')['signal'].to_dict()\n",
    "\n",
    "df['signal'] = df['itemid'].map(item_map)\n",
    "df = df.dropna(subset=['signal'])\n",
    "\n",
    "print(f\"✅ Mapped {df['signal'].nunique()} signals. Unique stay_ids: {df['stay_id'].nunique():,}\")\n",
    "\n",
    "# 3. Resample\n",
    "df['time_delta'] = pd.to_timedelta(df['hours_since_vaso'], unit='h')\n",
    "\n",
    "def process_stay(group):\n",
    "    wide = group.pivot_table(index='time_delta', columns='signal', values='valuenum', aggfunc='mean')\n",
    "    full_idx = pd.timedelta_range(start='0h', end='24h', freq=BIN_SIZE, closed='left')\n",
    "    wide = wide.reindex(full_idx).ffill(limit=6).bfill().fillna(0)\n",
    "    \n",
    "    # Engineer Shock Index (HR/SBP) & Pulse Pressure (SBP-DBP)\n",
    "    if 'HR' in wide.columns and 'SBP' in wide.columns:\n",
    "        wide['Shock_Index'] = wide['HR'] / wide['SBP'].replace(0, np.nan)\n",
    "    if 'SBP' in wide.columns and 'DBP' in wide.columns:\n",
    "        wide['Pulse_Pressure'] = wide['SBP'] - wide['DBP']\n",
    "        \n",
    "    return wide.iloc[:144].fillna(0)\n",
    "\n",
    "print(\"⏳ Resampling...\")\n",
    "tensor_df = df.groupby('stay_id').apply(process_stay)\n",
    "\n",
    "# 4. Save Tensor\n",
    "unique_stays = tensor_df.index.get_level_values(0).unique()\n",
    "X_tensor = tensor_df.values.reshape(len(unique_stays), 144, -1)\n",
    "\n",
    "# 5. Merge Labs (if you have them)\n",
    "try:\n",
    "    # Load the lab array we built previously to avoid re-processing\n",
    "    # We have to be careful: alignment must match unique_stays\n",
    "    # For safety, let's just save the Vitals tensor for now.\n",
    "    # You can re-run the \"Merge Labs\" block from the previous chat \n",
    "    # using this new tensor as 'X_base'.\n",
    "    pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "with open(f\"data/Sample_2/tensor_10min_enhanced.pkl\", 'wb') as f:\n",
    "    pickle.dump(X_tensor, f)\n",
    "with open(f\"data/Sample_2/tensor_stay_ids.pkl\", 'wb') as f:\n",
    "    pickle.dump(unique_stays.values, f)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"✅ Fixed Tensor Shape: {X_tensor.shape}\")\n",
    "print(f\"Features: {list(tensor_df.columns)}\") \n",
    "# Check: You should now see 7 vitals + 2 engineered = 9 features (before labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5176777b-b002-450d-b36a-5e4f2ae309a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Generating labels...\n",
      "⏳ Resampling BP data (this takes ~1-2 mins)...\n",
      "⏳ Calculating thresholds...\n",
      "------------------------------\n",
      "✅ Labels generated successfully!\n",
      "Saved to: data/Sample_2/hypotension_labels.csv.gz\n",
      "\n",
      "Class Balance:\n",
      "hypotension_label\n",
      "1.0    23638\n",
      "0.0     4875\n",
      "NaN        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIG ---\n",
    "DATA_DIR = \"data/Sample_2\"\n",
    "INPUT_CHART = f\"{DATA_DIR}/chartevents_vaso_24h_post.csv.gz\"\n",
    "INPUT_ITEMS = f\"{DATA_DIR}/d_items.csv.gz\"\n",
    "OUTPUT_LABELS = f\"{DATA_DIR}/hypotension_labels.csv.gz\"\n",
    "\n",
    "# Hyperparameters\n",
    "MAP_THRESHOLD = 65\n",
    "DURATION_MIN = 15\n",
    "BIN_SIZE = '5min' # Granular binning for label precision\n",
    "WINDOW_BINS = DURATION_MIN // 5 # 3 bins of 5 mins\n",
    "\n",
    "print(\"⏳ Generating labels...\")\n",
    "\n",
    "# 1. Load Data\n",
    "# We only need BP data\n",
    "df = pd.read_csv(INPUT_CHART, compression='gzip', usecols=['stay_id', 'charttime', 'itemid', 'valuenum'])\n",
    "df['charttime'] = pd.to_datetime(df['charttime'])\n",
    "\n",
    "# 2. Map IDs to MAP, SBP, DBP\n",
    "d_items = pd.read_csv(INPUT_ITEMS)\n",
    "# ... (Inside your label generation script) ...\n",
    "bp_map = {\n",
    "    r\"Mean Arterial Pressure|MAP|ABP mean|Blood Pressure.*mean\": \"MAP\",\n",
    "    r\"Systolic.*Blood Pressure|Blood Pressure.*Systolic|NBP S\": \"SBP\",\n",
    "    r\"Diastolic.*Blood Pressure|Blood Pressure.*Diastolic|NBP D\": \"DBP\",\n",
    "}\n",
    "# ... (Rest of script is same) ...\n",
    "def get_bp_type(label):\n",
    "    for pat, sig in bp_map.items():\n",
    "        if pd.notna(label) and pd.Series(label).str.contains(pat, case=False, regex=True).any():\n",
    "            return sig\n",
    "    return None\n",
    "\n",
    "d_items['bp_type'] = d_items['label'].apply(get_bp_type)\n",
    "item_map = d_items.dropna(subset=['bp_type']).set_index('itemid')['bp_type'].to_dict()\n",
    "\n",
    "df['bp_type'] = df['itemid'].map(item_map)\n",
    "df = df.dropna(subset=['bp_type'])\n",
    "\n",
    "# 3. Pivot to Time Series\n",
    "# We create a time-series per patient containing MAP, SBP, and DBP\n",
    "print(\"⏳ Resampling BP data (this takes ~1-2 mins)...\")\n",
    "pivot = df.pivot_table(index=['stay_id', 'charttime'], columns='bp_type', values='valuenum', aggfunc='mean')\n",
    "\n",
    "# 4. Calculate Labels per Patient\n",
    "def calculate_label(group):\n",
    "    # Resample to 5 min grid\n",
    "    # We use a relative time index to avoid timezone issues\n",
    "    group = group.droplevel(0)\n",
    "    group = group.resample(BIN_SIZE).mean()\n",
    "    \n",
    "    # Forward fill short gaps (up to 15 mins) to maintain continuity\n",
    "    group = group.ffill(limit=3)\n",
    "    \n",
    "    # A. Try Direct MAP\n",
    "    if 'MAP' in group.columns:\n",
    "        map_series = group['MAP']\n",
    "    else:\n",
    "        map_series = pd.Series(np.nan, index=group.index)\n",
    "        \n",
    "    # B. Fallback: Estimate MAP from SBP/DBP if MAP is NaN\n",
    "    # MAP ~ DBP + (SBP - DBP)/3\n",
    "    if 'SBP' in group.columns and 'DBP' in group.columns:\n",
    "        estimated_map = group['DBP'] + (group['SBP'] - group['DBP']) / 3.0\n",
    "        map_series = map_series.fillna(estimated_map)\n",
    "        \n",
    "    # C. Apply Logic: MAP < 65 for 3 consecutive bins (15 mins)\n",
    "    hypotensive_bins = (map_series < MAP_THRESHOLD).astype(int)\n",
    "    \n",
    "    # Rolling sum: if sum of 3 bins is 3, we have sustained hypotension\n",
    "    sustained = hypotensive_bins.rolling(window=WINDOW_BINS).sum()\n",
    "    is_hypotensive = (sustained >= WINDOW_BINS).any()\n",
    "    \n",
    "    # Return result\n",
    "    # Keep labeled as NaN if we had absolutely no BP data to judge\n",
    "    if map_series.notna().sum() == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return int(is_hypotensive)\n",
    "\n",
    "print(\"⏳ Calculating thresholds...\")\n",
    "labels = pivot.groupby('stay_id').apply(calculate_label)\n",
    "\n",
    "# 5. Save\n",
    "labels_df = labels.reset_index(name='hypotension_label')\n",
    "labels_df.to_csv(OUTPUT_LABELS, index=False, compression='gzip')\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"✅ Labels generated successfully!\")\n",
    "print(f\"Saved to: {OUTPUT_LABELS}\")\n",
    "print(\"\\nClass Balance:\")\n",
    "print(labels_df['hypotension_label'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ae1df6e-6c58-4329-a968-963d4b4b5d92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading components...\n",
      "⚠️ MISMATCH DETECTED: Tensor has 28735 rows, IDs has 28736.\n",
      "✂️ Trimming both to 28735 to sync...\n",
      "✅ Alignment: Found 28,511 patients with full data.\n",
      "------------------------------\n",
      "🎉 Ready. Train shape: (19957, 144, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- CONFIG ---\n",
    "DATA_DIR = \"data/Sample_2\"\n",
    "\n",
    "# 1. Load All Components\n",
    "print(\"⏳ Loading components...\")\n",
    "with open(f\"{DATA_DIR}/tensor_10min_w_labs.pkl\", 'rb') as f:\n",
    "    X_tensor_all = pickle.load(f)\n",
    "\n",
    "with open(f\"{DATA_DIR}/tensor_stay_ids.pkl\", 'rb') as f:\n",
    "    tensor_ids = pickle.load(f)\n",
    "\n",
    "# --- 🚨 SAFETY FIX FOR MISMATCH ---\n",
    "len_data = len(X_tensor_all)\n",
    "len_ids = len(tensor_ids)\n",
    "\n",
    "if len_data != len_ids:\n",
    "    print(f\"⚠️ MISMATCH DETECTED: Tensor has {len_data} rows, IDs has {len_ids}.\")\n",
    "    min_len = min(len_data, len_ids)\n",
    "    print(f\"✂️ Trimming both to {min_len} to sync...\")\n",
    "    X_tensor_all = X_tensor_all[:min_len]\n",
    "    tensor_ids = tensor_ids[:min_len]\n",
    "else:\n",
    "    print(f\"✅ Files are synced ({len_data} patients).\")\n",
    "\n",
    "# Load Static & Labels\n",
    "# Handle potential missing gender columns by dropping non-numeric types safely\n",
    "static_df = pd.read_csv(f\"{DATA_DIR}/static_fairness_data.csv.gz\")\n",
    "# Keep only numeric columns for the model (drops strings like 'M', 'WHITE')\n",
    "static_numeric = static_df.set_index('stay_id').select_dtypes(include=[np.number])\n",
    "# Drop IDs if they are numeric\n",
    "static_numeric = static_numeric.drop(['subject_id', 'hadm_id'], axis=1, errors='ignore')\n",
    "\n",
    "labels_df = pd.read_csv(f\"{DATA_DIR}/hypotension_labels.csv.gz\")\n",
    "\n",
    "# 2. Create Master Index\n",
    "valid_labels = labels_df.dropna(subset=['hypotension_label'])\n",
    "common_ids = set(tensor_ids) & set(static_numeric.index) & set(valid_labels['stay_id'])\n",
    "common_ids = sorted(list(common_ids))\n",
    "\n",
    "print(f\"✅ Alignment: Found {len(common_ids):,} patients with full data.\")\n",
    "\n",
    "# 3. Align Data\n",
    "id_to_tensor_idx = {sid: i for i, sid in enumerate(tensor_ids)}\n",
    "indices_to_keep = []\n",
    "aligned_static = []\n",
    "aligned_labels = []\n",
    "\n",
    "valid_labels = valid_labels.set_index('stay_id')\n",
    "\n",
    "for sid in common_ids:\n",
    "    indices_to_keep.append(id_to_tensor_idx[sid])\n",
    "    aligned_static.append(static_numeric.loc[sid].values.astype(float))\n",
    "    aligned_labels.append(valid_labels.loc[sid, 'hypotension_label'])\n",
    "\n",
    "# 4. Construct Numpy Arrays\n",
    "X_tensor = X_tensor_all[indices_to_keep]\n",
    "X_static = np.array(aligned_static)\n",
    "y = np.array(aligned_labels)\n",
    "\n",
    "# 5. Split\n",
    "X_tens_train, X_tens_temp, X_stat_train, X_stat_temp, y_train, y_temp = train_test_split(\n",
    "    X_tensor, X_static, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_tens_val, X_tens_test, X_stat_val, X_stat_test, y_val, y_test = train_test_split(\n",
    "    X_tens_temp, X_stat_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# 6. Save\n",
    "save_dict = {\n",
    "    \"X_tens_train\": X_tens_train, \"X_stat_train\": X_stat_train, \"y_train\": y_train,\n",
    "    \"X_tens_val\": X_tens_val,   \"X_stat_val\": X_stat_val,   \"y_val\": y_val,\n",
    "    \"X_tens_test\": X_tens_test, \"X_stat_test\": X_stat_test, \"y_test\": y_test,\n",
    "    \"feature_names_static\": list(static_numeric.columns)\n",
    "}\n",
    "\n",
    "with open(f\"{DATA_DIR}/model_ready_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(save_dict, f)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"🎉 Ready. Train shape: {X_tens_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67a589f1-b799-40ba-b0e7-2975d691368d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: {0.0: 3412, 1.0: 16545}\n",
      "Baseline Accuracy (if model guesses 1 for everyone): 0.8290\n",
      "✅ Data Normalized.\n",
      "⚖️ Calculated Class Weights: {0: 2.924531066822978, 1: 0.6031127228770021}\n",
      "\n",
      "🚀 Restarting Training (Normalized + Weighted)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_1' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 239ms/step - AUC: 0.5644 - accuracy: 0.5461 - loss: 0.6903 - val_AUC: 0.6067 - val_accuracy: 0.5588 - val_loss: 0.6859 - learning_rate: 5.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 241ms/step - AUC: 0.6059 - accuracy: 0.5759 - loss: 0.6767 - val_AUC: 0.6143 - val_accuracy: 0.5925 - val_loss: 0.6770 - learning_rate: 5.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 236ms/step - AUC: 0.6160 - accuracy: 0.5895 - loss: 0.6732 - val_AUC: 0.6192 - val_accuracy: 0.5925 - val_loss: 0.6749 - learning_rate: 5.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 235ms/step - AUC: 0.6265 - accuracy: 0.5960 - loss: 0.6692 - val_AUC: 0.6249 - val_accuracy: 0.6014 - val_loss: 0.6752 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 236ms/step - AUC: 0.6323 - accuracy: 0.6038 - loss: 0.6681 - val_AUC: 0.6257 - val_accuracy: 0.6133 - val_loss: 0.6698 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 239ms/step - AUC: 0.6283 - accuracy: 0.6066 - loss: 0.6681 - val_AUC: 0.6297 - val_accuracy: 0.5805 - val_loss: 0.6834 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 234ms/step - AUC: 0.6311 - accuracy: 0.5975 - loss: 0.6671 - val_AUC: 0.6259 - val_accuracy: 0.5698 - val_loss: 0.6887 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 235ms/step - AUC: 0.6333 - accuracy: 0.6008 - loss: 0.6660 - val_AUC: 0.6283 - val_accuracy: 0.6072 - val_loss: 0.6680 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 241ms/step - AUC: 0.6401 - accuracy: 0.6093 - loss: 0.6636 - val_AUC: 0.6266 - val_accuracy: 0.5735 - val_loss: 0.6933 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 243ms/step - AUC: 0.6407 - accuracy: 0.6141 - loss: 0.6638 - val_AUC: 0.6215 - val_accuracy: 0.5794 - val_loss: 0.6841 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 237ms/step - AUC: 0.6378 - accuracy: 0.6059 - loss: 0.6650 - val_AUC: 0.6273 - val_accuracy: 0.5749 - val_loss: 0.6870 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 238ms/step - AUC: 0.6433 - accuracy: 0.6034 - loss: 0.6614 - val_AUC: 0.6257 - val_accuracy: 0.5899 - val_loss: 0.6796 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 239ms/step - AUC: 0.6446 - accuracy: 0.6088 - loss: 0.6611 - val_AUC: 0.6239 - val_accuracy: 0.6030 - val_loss: 0.6682 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 241ms/step - AUC: 0.6466 - accuracy: 0.6104 - loss: 0.6599 - val_AUC: 0.6230 - val_accuracy: 0.6044 - val_loss: 0.6696 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# --- 1. CHECK FOR \"LAZY PREDICTOR\" (Sanity Check) ---\n",
    "# Let's verify your class balance\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"Class Counts: {dict(zip(unique, counts))}\")\n",
    "majority_class_pct = max(counts) / sum(counts)\n",
    "print(f\"Baseline Accuracy (if model guesses 1 for everyone): {majority_class_pct:.4f}\")\n",
    "# If this matches your val_accuracy (0.8291), the diagnosis is confirmed.\n",
    "\n",
    "# --- 2. NORMALIZE DATA (Critical for Neural Nets) ---\n",
    "# We reshape to 2D, scale, and reshape back to 3D\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train scaling (Fit on Train only to avoid leakage)\n",
    "N, T, F = X_train_ts.shape\n",
    "X_train_ts_flat = X_train_ts.reshape(-1, F)\n",
    "X_train_ts_scaled = scaler.fit_transform(X_train_ts_flat).reshape(N, T, F)\n",
    "\n",
    "# Val scaling (Transform only)\n",
    "N_val = X_val_ts.shape[0]\n",
    "X_val_ts_scaled = scaler.transform(X_val_ts.reshape(-1, F)).reshape(N_val, T, F)\n",
    "\n",
    "# Static scaling\n",
    "scaler_st = StandardScaler()\n",
    "X_train_st_scaled = scaler_st.fit_transform(X_train_st)\n",
    "X_val_st_scaled = scaler_st.transform(X_val_st)\n",
    "\n",
    "print(\"✅ Data Normalized.\")\n",
    "\n",
    "# --- 3. COMPUTE CLASS WEIGHTS ---\n",
    "# This penalizes the model more for missing the minority class\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(weights))\n",
    "print(f\"⚖️ Calculated Class Weights: {class_weights}\")\n",
    "\n",
    "# --- 4. RE-DEFINE MODEL (Slightly Tuned) ---\n",
    "# Increased Dropout to prevent overfitting now that it will actually learn\n",
    "def build_tuned_transformer(ts_input_shape, st_input_shape):\n",
    "    ts_inputs = keras.Input(shape=ts_input_shape, name=\"timeseries_input\")\n",
    "    \n",
    "    # Masking\n",
    "    x = layers.Masking(mask_value=0.0)(ts_inputs)\n",
    "    \n",
    "    # Transformer\n",
    "    attention = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x) # Increased key_dim\n",
    "    x = layers.Add()([x, attention])\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    # Temporal Conv\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Static\n",
    "    st_inputs = keras.Input(shape=st_input_shape, name=\"static_input\")\n",
    "    y = layers.Dense(32, activation=\"relu\")(st_inputs)\n",
    "    \n",
    "    # Fusion\n",
    "    combined = layers.Concatenate()([x, y])\n",
    "    z = layers.Dense(64, activation=\"relu\")(combined)\n",
    "    z = layers.Dropout(0.5)(z) # Higher dropout\n",
    "    \n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "    \n",
    "    return keras.Model(inputs=[ts_inputs, st_inputs], outputs=outputs)\n",
    "\n",
    "model = build_tuned_transformer(X_train_ts.shape[1:], X_train_st.shape[1:])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005), # Lower LR for stability\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"AUC\", \"accuracy\"]\n",
    ")\n",
    "\n",
    "# --- 5. TRAIN WITH WEIGHTS ---\n",
    "print(\"\\n🚀 Restarting Training (Normalized + Weighted)...\")\n",
    "history = model.fit(\n",
    "    x=[X_train_ts_scaled, X_train_st_scaled],\n",
    "    y=y_train,\n",
    "    validation_data=([X_val_ts_scaled, X_val_st_scaled], y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights, # <--- The Magic Ingredient\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1fb9c4-c1d2-41fc-9673-1c9bcc1ea44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m136",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m136"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
